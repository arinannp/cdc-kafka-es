apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker-ver324
  namespace: my-spark-project
  labels:
    app: spark-worker-ver324
spec:
  replicas: 2
  selector:
    matchLabels:
      app: spark-worker-ver324
  template:
    metadata:
      labels:
        app: spark-worker-ver324
    spec:
      containers:
        - name: spark-worker-ver324
          image: bitnami/spark:3.2.4
          imagePullPolicy: IfNotPresent
          env:
            - name: SPARK_MODE
              value: "worker"
            - name: SPARK_MASTER_URL
              value: "spark://spark-ver324-cip-svc:7077"
            - name: SPARK_WORKER_MEMORY
              value: "1G"
            - name: SPARK_WORKER_CORES
              value: "1"
            - name: SPARK_RPC_AUTHENTICATION_ENABLED
              value: "no"
            - name: SPARK_RPC_ENCRYPTION_ENABLED
              value: "no"
            - name: SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED
              value: "no"
            - name: SPARK_SSL_ENABLED
              value: "no"
            - name: SPARK_USER
              value: "root"
            - name: POSTGRES_USER
              value: "debezium"
            - name: POSTGRES_PASSWORD
              value: "debezium"
            - name: POSTGRES_DB
              value: "debezium_db"
            - name: POSTGRES_HOST
              value: "postgres-np-svc.my-postgres-project:5432"
            - name: TABLE_DEST
              value: "public.person_churn_history_captured"
            - name: BOOTSTRAP_SERVER
              value: my-cluster-kafka-kafka-external-bootstrap.my-kafka-project:9094
            - name: TOPIC_NAME
              value: debeziumconn.public.person_churn_history
            - name: TOPIC_NAME_DEST
              value: person_churn_history_predicted
          volumeMounts: 
            # https://kubernetes.io/docs/concepts/storage/volumes/#:~:text=hostPath%20FileOrCreate%20configuration%20example
            - name: spark-connector
              mountPath: /opt/bitnami/spark/project/connector
            - name: spark-script
              mountPath: /opt/bitnami/spark/project/
            - name: spark-input
              mountPath: /opt/bitnami/spark/project/source
            - name: spark-output
              mountPath: /opt/bitnami/spark/project/output
      volumes:
        - name: spark-connector
          hostPath:
            # Ensure the file directory is created.
            type: DirectoryOrCreate
            # If you have Docker Desktop installed on Windows using WSL, you can use these path:
            # /run/desktop/mnt/host/c/PATH_TO_FOLDER/
            # Otherwise, if you use Mac, Linux or Windows installed using Hyper-V, you can follow these step:
            # https://julien-chen.medium.com/k8s-how-to-mount-local-directory-persistent-volume-to-kubernetes-pods-of-docker-desktop-for-mac-b72f3ca6b0dd
            path: "PATH_TO_THIS_FOLDER_ON_YOUR_LOCAL https://github.com/arinannp/cdc-kafka-es/tree/main/spark/script/connector"
        - name: spark-script
          hostPath:
            # If you have Docker Desktop installed on Windows using WSL, you can use these path:
            # /run/desktop/mnt/host/c/PATH_TO_FOLDER/
            # Otherwise, if you use Mac, Linux or Windows installed using Hyper-V, you can follow these step:
            # https://julien-chen.medium.com/k8s-how-to-mount-local-directory-persistent-volume-to-kubernetes-pods-of-docker-desktop-for-mac-b72f3ca6b0dd
            path: "PATH_TO_THIS_FOLDER_ON_YOUR_LOCAL https://github.com/arinannp/cdc-kafka-es/tree/main/spark/script"
        - name: spark-input
          hostPath:
            type: DirectoryOrCreate
            # If you have Docker Desktop installed on Windows using WSL, you can use these path:
            # /run/desktop/mnt/host/c/PATH_TO_FOLDER/
            # Otherwise, if you use Mac, Linux or Windows installed using Hyper-V, you can follow these step:
            # https://julien-chen.medium.com/k8s-how-to-mount-local-directory-persistent-volume-to-kubernetes-pods-of-docker-desktop-for-mac-b72f3ca6b0dd
            path: "PATH_TO_THIS_FOLDER_ON_YOUR_LOCAL https://github.com/arinannp/cdc-kafka-es/tree/main/spark/script/source"
        - name: spark-output
          hostPath:
            type: DirectoryOrCreate
            # If you have Docker Desktop installed on Windows using WSL, you can use these path:
            # /run/desktop/mnt/host/c/PATH_TO_FOLDER/
            # Otherwise, if you use Mac, Linux or Windows installed using Hyper-V, you can follow these step:
            # https://julien-chen.medium.com/k8s-how-to-mount-local-directory-persistent-volume-to-kubernetes-pods-of-docker-desktop-for-mac-b72f3ca6b0dd
            path: "PATH_TO_THIS_FOLDER_ON_YOUR_LOCAL https://github.com/arinannp/cdc-kafka-es/tree/main/spark/script/output"
      restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: spark-client-worker
  namespace: my-spark-project
spec:
  selector:
    app: spark-worker-ver324
  clusterIP: None